{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:39:48.340375Z",
     "iopub.status.busy": "2025-01-08T14:39:48.340067Z",
     "iopub.status.idle": "2025-01-08T14:39:56.126682Z",
     "shell.execute_reply": "2025-01-08T14:39:56.125347Z",
     "shell.execute_reply.started": "2025-01-08T14:39:48.340353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:39:56.128607Z",
     "iopub.status.busy": "2025-01-08T14:39:56.128278Z",
     "iopub.status.idle": "2025-01-08T14:40:04.635282Z",
     "shell.execute_reply": "2025-01-08T14:40:04.634377Z",
     "shell.execute_reply.started": "2025-01-08T14:39:56.128578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:04.637939Z",
     "iopub.status.busy": "2025-01-08T14:40:04.637310Z",
     "iopub.status.idle": "2025-01-08T14:40:06.247996Z",
     "shell.execute_reply": "2025-01-08T14:40:06.247101Z",
     "shell.execute_reply.started": "2025-01-08T14:40:04.637912Z"
    },
    "id": "yBjCJ6M-Uc3K",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import layers, saving\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow import data as tf_data\n",
    "import albumentations as A\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "data_path = \"/kaggle/input/filtered-clouds/CCSN_filtered_224/\"\n",
    "test_path = data_path+\"test\"\n",
    "name_suffix = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:06.250165Z",
     "iopub.status.busy": "2025-01-08T14:40:06.249544Z",
     "iopub.status.idle": "2025-01-08T14:40:06.255430Z",
     "shell.execute_reply": "2025-01-08T14:40:06.254185Z",
     "shell.execute_reply.started": "2025-01-08T14:40:06.250113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:06.256649Z",
     "iopub.status.busy": "2025-01-08T14:40:06.256377Z",
     "iopub.status.idle": "2025-01-08T14:40:09.609560Z",
     "shell.execute_reply": "2025-01-08T14:40:09.608897Z",
     "shell.execute_reply.started": "2025-01-08T14:40:06.256621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "IMAGE_SIZE_299 = (299, 299)\n",
    "\n",
    "train_dataset, val_dataset = keras.utils.image_dataset_from_directory(\n",
    "    data_path+\"train\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.1,\n",
    "    subset='both',\n",
    "    seed=42,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")\n",
    "\n",
    "train_dataset299, val_dataset299 = keras.utils.image_dataset_from_directory(\n",
    "    data_path+\"train\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.1,\n",
    "    subset='both',\n",
    "    seed=42,\n",
    "    image_size=IMAGE_SIZE_299,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:09.610582Z",
     "iopub.status.busy": "2025-01-08T14:40:09.610370Z",
     "iopub.status.idle": "2025-01-08T14:40:09.746681Z",
     "shell.execute_reply": "2025-01-08T14:40:09.746054Z",
     "shell.execute_reply.started": "2025-01-08T14:40:09.610564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = keras.utils.image_dataset_from_directory(\n",
    "    test_path,\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")\n",
    "\n",
    "test_dataset299 = keras.utils.image_dataset_from_directory(\n",
    "    data_path+\"test\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE_299,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:09.747648Z",
     "iopub.status.busy": "2025-01-08T14:40:09.747425Z",
     "iopub.status.idle": "2025-01-08T14:40:09.753585Z",
     "shell.execute_reply": "2025-01-08T14:40:09.752878Z",
     "shell.execute_reply.started": "2025-01-08T14:40:09.747628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_text = sorted(os.listdir(test_path))\n",
    "labels_dict = {i: name for i, name in zip(range(len(labels_text)), labels_text)}\n",
    "labels_text_to_num = {name: i for i, name in zip(range(len(labels_text)), labels_text)}\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:09.756380Z",
     "iopub.status.busy": "2025-01-08T14:40:09.756121Z",
     "iopub.status.idle": "2025-01-08T14:40:11.410569Z",
     "shell.execute_reply": "2025-01-08T14:40:11.409514Z",
     "shell.execute_reply.started": "2025-01-08T14:40:09.756350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_imgs_ds(ds):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 8)\n",
    "    axes = *ax1, *ax2\n",
    "    fig.set_size_inches(20, 5)\n",
    "    for i, (imgs, labels) in enumerate(ds):\n",
    "        if i > 0:\n",
    "            break\n",
    "        \n",
    "        for ax, img, label in zip(axes, imgs, labels):\n",
    "            ax.set_title(labels_dict.get(int(np.argmax(label, axis=-1)), \"Error\"))\n",
    "            ax.axis(\"off\")\n",
    "            img = np.array(img)\n",
    "            if np.max(img) > 1:\n",
    "                ax.imshow(img.astype(np.uint8))\n",
    "            elif np.min(img) < 0:\n",
    "                ax.imshow(((img+1)*127.5).astype(np.uint8))\n",
    "            else:\n",
    "                ax.imshow((img*255).astype(np.uint8))\n",
    "\n",
    "sample = train_dataset.take(1)\n",
    "show_imgs_ds(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:11.411966Z",
     "iopub.status.busy": "2025-01-08T14:40:11.411737Z",
     "iopub.status.idle": "2025-01-08T14:40:11.458679Z",
     "shell.execute_reply": "2025-01-08T14:40:11.458061Z",
     "shell.execute_reply.started": "2025-01-08T14:40:11.411947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@saving.register_keras_serializable(\"Custom\")\n",
    "class PreprocessingLayerResnet(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PreprocessingLayerResnet, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PreprocessingLayerResnet, self).get_config()\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        outputs = keras.applications.resnet.preprocess_input(inputs)\n",
    "        outputs.set_shape(inputs.shape)\n",
    "        return outputs\n",
    "\n",
    "@saving.register_keras_serializable(\"Custom\")\n",
    "class PreprocessingLayerXception(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PreprocessingLayerXception, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PreprocessingLayerXception, self).get_config()\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        outputs = keras.applications.xception.preprocess_input(inputs)\n",
    "        outputs.set_shape(inputs.shape)\n",
    "        return outputs\n",
    "\n",
    "@saving.register_keras_serializable(\"Custom\")\n",
    "class AugmentationLayer(layers.Layer):\n",
    "    def __init__(self, transforms=None, **kwargs):\n",
    "        super(AugmentationLayer, self).__init__(**kwargs)\n",
    "        if transforms is None:\n",
    "            self.transforms = A.Compose([])\n",
    "        else:\n",
    "            self.transforms = transforms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(AugmentationLayer, self).get_config()\n",
    "        return config\n",
    "\n",
    "    @tf.function\n",
    "    def augment_image(self, image):\n",
    "        def _augment(image_np):\n",
    "            augmented = self.transforms(image=image_np/255)\n",
    "            return augmented[\"image\"].astype(np.float32)*255\n",
    "\n",
    "        image_aug = tf.numpy_function(func=_augment, inp=[image], Tout=tf.float32)\n",
    "        return image_aug\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            outputs = tf.map_fn(self.augment_image, inputs, dtype=tf.float32)\n",
    "            outputs.set_shape(inputs.shape)\n",
    "            return outputs\n",
    "\n",
    "        return inputs\n",
    "\n",
    "aug = A.Compose([\n",
    "    A.Perspective(p=0.5, scale=(0, 0.25)),\n",
    "    A.GridDistortion(p=0.3),\n",
    "    A.ElasticTransform(p=0.3),\n",
    "    A.UnsharpMask(p=0.3),\n",
    "    A.GaussianBlur(p=0.15, blur_limit=[3,5]),\n",
    "    A.ColorJitter(p=1.0, brightness=[0.7,1.2], contrast=[0.8,1.3], saturation=[0.8,1.2], hue=[-0.06,0.06]),\n",
    "    A.RandomGamma(p=0.2),\n",
    "    A.RandomShadow(p=0.25, shadow_roi=[0, 0.6, 1, 1], num_shadows_limit=[1,1], shadow_dimension=4, shadow_intensity_range=[1.0,1.0]),\n",
    "    A.GaussNoise(p=0.15, var_limit=[5e-4,1e-3], per_channel=False),\n",
    "])\n",
    "\n",
    "augmentation_layer = AugmentationLayer(transforms=aug)\n",
    "full_augmentation_layer = keras.models.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom((-0.25, 0.15)),\n",
    "    augmentation_layer,\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "augmentation_layer299 = AugmentationLayer(transforms=aug)\n",
    "full_augmentation_layer299 = keras.models.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom((-0.25, 0.15)),\n",
    "    augmentation_layer299,\n",
    "], name=\"data_augmentation299\")\n",
    "\n",
    "min_augmentation_layer = keras.models.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom((-0.25, 0.15)),\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:11.459522Z",
     "iopub.status.busy": "2025-01-08T14:40:11.459328Z",
     "iopub.status.idle": "2025-01-08T14:40:16.119998Z",
     "shell.execute_reply": "2025-01-08T14:40:16.119080Z",
     "shell.execute_reply.started": "2025-01-08T14:40:11.459504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def augment(augmentation_layer):\n",
    "    return lambda image, label: (augmentation_layer(image, training=True), label)\n",
    "\n",
    "\n",
    "sample = train_dataset.take(1)\n",
    "aug_sample = sample.map(augment(full_augmentation_layer))\n",
    "show_imgs_ds(aug_sample)\n",
    "\n",
    "sample = train_dataset.take(1)\n",
    "aug_sample = sample.map(augment(full_augmentation_layer))\n",
    "show_imgs_ds(aug_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:16.121575Z",
     "iopub.status.busy": "2025-01-08T14:40:16.121255Z",
     "iopub.status.idle": "2025-01-08T14:40:18.363304Z",
     "shell.execute_reply": "2025-01-08T14:40:18.362414Z",
     "shell.execute_reply.started": "2025-01-08T14:40:16.121546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for image, _ in sample:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = image[random.randint(0, BATCH_SIZE)]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = full_augmentation_layer(tf.expand_dims(first_image, 0), training=True)\n",
    "        plt.imshow(augmented_image[0] / 255)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:18.364560Z",
     "iopub.status.busy": "2025-01-08T14:40:18.364263Z",
     "iopub.status.idle": "2025-01-08T14:40:18.370342Z",
     "shell.execute_reply": "2025-01-08T14:40:18.369499Z",
     "shell.execute_reply.started": "2025-01-08T14:40:18.364531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(history, out_path_loss, out_path_acc):\n",
    "    epochs = range(len(history.history[\"loss\"]))\n",
    "    plt.figure()\n",
    "    plt.title(\"Loss history\")\n",
    "    plt.plot(epochs, history.history[\"loss\"], label=\"Training loss\")\n",
    "    plt.plot(epochs, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(out_path_loss)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Accuracy history\")\n",
    "    plt.plot(epochs, history.history[\"acc\"], label=\"Training accuracy\")\n",
    "    plt.plot(epochs, history.history[\"val_acc\"], label=\"Validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(out_path_acc)\n",
    "    plt.show()\n",
    "\n",
    "def print_layers(conv_base, freeze_point):\n",
    "    print(\"=============================\")\n",
    "    for layer in conv_base.layers[:freeze_point]:\n",
    "        print(layer.name)\n",
    "\n",
    "    print(\"-----------------------------\")\n",
    "    for layer in conv_base.layers[freeze_point:]:\n",
    "        print(layer.name)\n",
    "\n",
    "    return conv_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:18.371703Z",
     "iopub.status.busy": "2025-01-08T14:40:18.371375Z",
     "iopub.status.idle": "2025-01-08T14:40:20.877469Z",
     "shell.execute_reply": "2025-01-08T14:40:20.876631Z",
     "shell.execute_reply.started": "2025-01-08T14:40:18.371669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_y(ds):\n",
    "    y = []\n",
    "    for _, labels in ds:\n",
    "        for label in labels:\n",
    "            y.append(np.argmax(label, axis=-1))\n",
    "    return y\n",
    "\n",
    "y_train = get_y(train_dataset)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:20.878483Z",
     "iopub.status.busy": "2025-01-08T14:40:20.878258Z",
     "iopub.status.idle": "2025-01-08T14:40:27.770763Z",
     "shell.execute_reply": "2025-01-08T14:40:27.769864Z",
     "shell.execute_reply.started": "2025-01-08T14:40:20.878464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = IMAGE_SIZE + (3,)\n",
    "IMG_SHAPE_299 = IMAGE_SIZE_299 + (3,)\n",
    "\n",
    "def create_model_cn_tiny(dropout, augmentation_layer):\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.00005,\n",
    "        decay_steps=5000,\n",
    "        decay_rate=0.2)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    input_tensor = keras.Input(shape=IMG_SHAPE)\n",
    "    x = augmentation_layer(input_tensor)\n",
    "    \n",
    "    conv_base = keras.applications.convnext.ConvNeXtTiny(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)\n",
    "    conv_base.name = \"base_model\"\n",
    "    conv_base.trainable = True\n",
    "    for layer in conv_base.layers[:len(conv_base.layers) // 3 + 3]:\n",
    "        layer.trainable =  False\n",
    "\n",
    "    x = conv_base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(128, activation='gelu', kernel_regularizer=keras.regularizers.l2(0.006))(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    predictions = layers.Dense(11, activation='softmax')(x)\n",
    "    model = keras.models.Model(inputs=input_tensor, outputs=predictions)\n",
    "    model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=optimizer, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def create_model_xception(dropout, augmentation_layer):\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.0001,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.1)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    input_tensor = keras.Input(shape=IMG_SHAPE_299)\n",
    "    x = augmentation_layer(input_tensor)\n",
    "    x = PreprocessingLayerXception()(x)\n",
    "    \n",
    "    conv_base = keras.applications.Xception(weights='imagenet', include_top=False, input_shape=IMG_SHAPE_299)\n",
    "    conv_base.trainable = True\n",
    "    for layer in conv_base.layers[:len(conv_base.layers) // 3 + 1]:\n",
    "        layer.trainable =  False\n",
    "\n",
    "    x = conv_base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(128, activation='elu', kernel_regularizer=keras.regularizers.L2(0.008))(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    predictions = layers.Dense(11, activation='softmax')(x)\n",
    "    model = keras.models.Model(inputs=input_tensor, outputs=predictions)\n",
    "    model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=optimizer, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def create_model_resnet(dropout, augmentation_layer):\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.0001,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.1)\n",
    "    optimizer = keras.optimizers.Nadam(learning_rate=lr_schedule)\n",
    "    \n",
    "    input_tensor = keras.Input(shape=IMG_SHAPE)\n",
    "    x = augmentation_layer(input_tensor)\n",
    "    x = PreprocessingLayerResnet()(x)\n",
    "    \n",
    "    conv_base = keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)\n",
    "    conv_base.trainable = True\n",
    "    for layer in conv_base.layers[:len(conv_base.layers) // 4]:\n",
    "        layer.trainable =  False\n",
    "    conv_base.name = \"base_model\"\n",
    "    keras.utils.plot_model(conv_base, to_file='blocks_resnet.png')\n",
    "\n",
    "    x = conv_base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    predictions = layers.Dense(11, activation='softmax')(x)\n",
    "    model = keras.models.Model(inputs=input_tensor, outputs=predictions)\n",
    "    model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=optimizer, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model_cn = create_model_cn_tiny(0.2, full_augmentation_layer)\n",
    "model_xc = create_model_xception(0.6, full_augmentation_layer299)\n",
    "model_rn = create_model_resnet(0.4, full_augmentation_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:40:27.771976Z",
     "iopub.status.busy": "2025-01-08T14:40:27.771675Z",
     "iopub.status.idle": "2025-01-08T14:45:20.281611Z",
     "shell.execute_reply": "2025-01-08T14:45:20.280767Z",
     "shell.execute_reply.started": "2025-01-08T14:40:27.771941Z"
    },
    "id": "kqo3b-NfUc3U",
    "outputId": "64137df9-3d85-4709-9652-4f3e22238d8f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_dataset, val_dataset, epochs, patience):\n",
    "    train_dataset = train_dataset.prefetch(tf_data.AUTOTUNE)\n",
    "    val_dataset = val_dataset.prefetch(tf_data.AUTOTUNE)\n",
    "    return model.fit(\n",
    "        train_dataset,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_dataset,\n",
    "        class_weight=class_weights_dict,\n",
    "        callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)]), model\n",
    "\n",
    "history, model_cn = train(model_cn, train_dataset, val_dataset, 200, patience=20)\n",
    "plot_loss_acc(history, \"/kaggle/working/loss_\"+name_suffix+\"_cn_tiny\"+\".png\", \"/kaggle/working/acc_\"+name_suffix+\"_cn_tiny\"+\".png\")\n",
    "\n",
    "history, model_xc = train(model_xc, train_dataset299, val_dataset299, 200, patience=20)\n",
    "plot_loss_acc(history, \"/kaggle/working/loss_\"+name_suffix+\"_xception\"+\".png\", \"/kaggle/working/acc_\"+name_suffix+\"_xception\"+\".png\")\n",
    "\n",
    "\n",
    "history, model_rn = train(model_rn, train_dataset, val_dataset, 200, patience=20)\n",
    "plot_loss_acc(history, \"/kaggle/working/loss_\"+name_suffix+\"_resnet\"+\".png\", \"/kaggle/working/acc_\"+name_suffix+\"_resnet\"+\".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:45:20.282779Z",
     "iopub.status.busy": "2025-01-08T14:45:20.282454Z",
     "iopub.status.idle": "2025-01-08T14:45:24.575028Z",
     "shell.execute_reply": "2025-01-08T14:45:24.573982Z",
     "shell.execute_reply.started": "2025-01-08T14:45:20.282744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_cn.save(\"/kaggle/working/classifier_cn.keras\")\n",
    "model_xc.save(\"/kaggle/working/classifier_xc.keras\")\n",
    "model_rn.save(\"/kaggle/working/classifier_rn.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:45:24.576545Z",
     "iopub.status.busy": "2025-01-08T14:45:24.576196Z",
     "iopub.status.idle": "2025-01-08T14:45:32.189467Z",
     "shell.execute_reply": "2025-01-08T14:45:32.188598Z",
     "shell.execute_reply.started": "2025-01-08T14:45:24.576505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_imgs_list(imgs, labels, wrong_labels):\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 8)\n",
    "    axes = *ax1, *ax2, *ax3, *ax4\n",
    "    fig.set_size_inches(20, 10)\n",
    "    for ax, img, label, wrong_label in zip(axes, imgs, labels, wrong_labels):\n",
    "        ax.set_title(labels_dict.get(int(np.argmax(label, axis=-1)), \"Error\") + \" vs pred: \" + labels_dict.get(int(np.argmax(wrong_label, axis=-1)), \"Error\"))\n",
    "        ax.axis(\"off\")\n",
    "        img = np.array(img)\n",
    "        ax.imshow(img.astype(np.uint8))\n",
    "\n",
    "test_imgs = []\n",
    "test_labels = []\n",
    "for imgs, labels in test_dataset:\n",
    "    for img, label in zip(imgs, labels):\n",
    "        test_imgs.append(img)\n",
    "        test_labels.append(label)\n",
    "\n",
    "x_test, y_test = np.array(test_imgs), np.array(test_labels)\n",
    "\n",
    "test_imgs299 = []\n",
    "test_labels299 = []\n",
    "for imgs, labels in test_dataset299:\n",
    "    for img, label in zip(imgs, labels):\n",
    "        test_imgs299.append(img)\n",
    "        test_labels299.append(label)\n",
    "\n",
    "x_test299, y_test299 = np.array(test_imgs299), np.array(test_labels299)\n",
    "\n",
    "score1 = model_cn.evaluate(x_test, y_test)\n",
    "print(\"Accuracy on test dataset ConvNeXt:\", score1[1])\n",
    "score2 = model_xc.evaluate(x_test299, y_test299)\n",
    "print(\"Accuracy on test dataset Xception:\", score2[1])\n",
    "score3 = model_rn.evaluate(x_test, y_test)\n",
    "print(\"Accuracy on test dataset ResNet:\", score3[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:45:32.190878Z",
     "iopub.status.busy": "2025-01-08T14:45:32.190531Z",
     "iopub.status.idle": "2025-01-08T14:45:40.175440Z",
     "shell.execute_reply": "2025-01-08T14:45:40.174266Z",
     "shell.execute_reply.started": "2025-01-08T14:45:32.190845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_labels = model_cn.predict(x_test)\n",
    "misclassified_indices = np.argmax(predicted_labels, axis=-1) != np.argmax(y_test, axis=-1)\n",
    "show_imgs_list(x_test[misclassified_indices], y_test[misclassified_indices], predicted_labels[misclassified_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:45:40.176679Z",
     "iopub.status.busy": "2025-01-08T14:45:40.176409Z",
     "iopub.status.idle": "2025-01-08T14:45:51.778608Z",
     "shell.execute_reply": "2025-01-08T14:45:51.777692Z",
     "shell.execute_reply.started": "2025-01-08T14:45:40.176654Z"
    },
    "id": "aqMwjI4bUc3Y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_cm(model, x, y, out_name):\n",
    "    y_test_pred = model.predict(x)\n",
    "    y_test_pred_cls = [np.argmax(sample) for sample in y_test_pred]\n",
    "    cm = confusion_matrix(y, y_test_pred_cls, labels=list(labels_dict.keys()))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(labels_dict.values()))\n",
    "    disp.plot()\n",
    "    plt.savefig(\"/kaggle/working/test_confusion_matrix_\"+out_name+\"_\"+name_suffix+\".png\")\n",
    "    plt.show()\n",
    "\n",
    "show_cm(model_cn, x_test, [np.argmax(label) for label in y_test], \"convnext\")\n",
    "show_cm(model_xc, x_test299, [np.argmax(label) for label in y_test299], \"xception\")\n",
    "show_cm(model_rn, x_test, [np.argmax(label) for label in y_test], \"resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:45:51.780008Z",
     "iopub.status.busy": "2025-01-08T14:45:51.779667Z",
     "iopub.status.idle": "2025-01-08T14:45:51.799576Z",
     "shell.execute_reply": "2025-01-08T14:45:51.798668Z",
     "shell.execute_reply.started": "2025-01-08T14:45:51.779960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=IMAGE_SIZE)\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    return img_array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = keras.models.Model(\n",
    "        model.input, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_gradcam(img, heatmap, cam_path, alpha=0.3):\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = plt.colormaps[\"jet\"]\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "    superimposed_img.save(cam_path)\n",
    "    return jet_colors[heatmap], superimposed_img\n",
    "\n",
    "\n",
    "image_paths = [\n",
    "    test_path+\"/Ac/\" + os.listdir(test_path+\"/Ac/\")[0],\n",
    "    test_path+\"/As/\" + os.listdir(test_path+\"/As/\")[0],\n",
    "    test_path+\"/Cb/\" + os.listdir(test_path+\"/Cb/\")[0],\n",
    "    test_path+\"/Cc/\" + os.listdir(test_path+\"/Cc/\")[0],\n",
    "    test_path+\"/Ci/\" + os.listdir(test_path+\"/Ci/\")[0],\n",
    "    test_path+\"/Cs/\" + os.listdir(test_path+\"/Cs/\")[0],\n",
    "    test_path+\"/Ct/\" + os.listdir(test_path+\"/Ct/\")[0],\n",
    "    test_path+\"/Cu/\" + os.listdir(test_path+\"/Cu/\")[0],\n",
    "    test_path+\"/Ns/\" + os.listdir(test_path+\"/Ns/\")[0],\n",
    "    test_path+\"/Sc/\" + os.listdir(test_path+\"/Sc/\")[0],\n",
    "    test_path+\"/St/\" + os.listdir(test_path+\"/St/\")[0],\n",
    "]\n",
    "# imgs = []\n",
    "# for path in image_paths:\n",
    "#     imgs.append(preprocess_image(path))\n",
    "\n",
    "# img_array = np.array(imgs)\n",
    "# last_conv_layer_name = \"convnext_tiny_stage_3_block_2_identity\"\n",
    "# model_cn.layers[-1].activation = None\n",
    "\n",
    "# preds = model_cn.predict(img_array)\n",
    "# for i, pred in enumerate(preds):\n",
    "#     print(\"Predicted:\", labels_dict.get(np.argmax(pred)))\n",
    "#     gradcam_heatmap = make_gradcam_heatmap(np.array([img_array[i]]), model_cn, last_conv_layer_name)\n",
    "#     heatmap, superimposed_img = save_gradcam(img_array[i], gradcam_heatmap, \"/kaggle/working/\"+\"cam\"+str(i)+\".jpg\")\n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "#     fig.set_size_inches(10, 4)\n",
    "#     ax1.imshow(superimposed_img)\n",
    "#     ax1.axis('off')\n",
    "#     ax2.imshow(img_array[i]/255)\n",
    "#     ax2.axis('off')\n",
    "#     ax3.imshow(heatmap)\n",
    "#     ax3.axis('off')\n",
    "\n",
    "# model_cn.layers[-1].activation = 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6366112,
     "sourceId": 10287007,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6379089,
     "sourceId": 10305286,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6385914,
     "sourceId": 10315064,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6430306,
     "sourceId": 10380388,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 205177,
     "modelInstanceId": 182976,
     "sourceId": 214636,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
